# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2015, Orange Data Mining
# This file is distributed under the same license as the Orange Data Mining
# Library package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Orange Data Mining Library 3\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2018-10-29 15:50+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../source/tutorial/classification.rst:2
msgid "Classification"
msgstr ""

#: ../../source/tutorial/classification.rst:8
msgid ""
"Much of Orange is devoted to machine learning methods for classification,"
" or supervised data mining. These methods rely on data with class-labeled"
" instances, like that of senate voting. Here is a code that loads this "
"dataset, displays the first data instance and shows its predicted class "
"(``republican``)::"
msgstr ""

#: ../../source/tutorial/classification.rst:15
msgid ""
"Orange implements functions for construction of classification models, "
"their evaluation and scoring. In a nutshell, here is the code that "
"reports on cross-validated accuracy and AUC for logistic regression and "
"random forests:"
msgstr ""

#: ../../source/tutorial/classification.rst:19
msgid "It turns out that for this domain logistic regression does well::"
msgstr ""

#: ../../source/tutorial/classification.rst:24
msgid ""
"For supervised learning, Orange uses learners. These are objects that "
"receive the data and return classifiers. Learners are passed to "
"evaluation routines, such as cross-validation above."
msgstr ""

#: ../../source/tutorial/classification.rst:27
msgid "Learners and Classifiers"
msgstr ""

#: ../../source/tutorial/classification.rst:36
msgid ""
"Classification uses two types of objects: learners and classifiers. "
"Learners consider class-labeled data and return a classifier. Given the "
"first three data instances, classifiers return the indexes of predicted "
"class::"
msgstr ""

#: ../../source/tutorial/classification.rst:45
msgid ""
"Above, we read the data, constructed a logistic regression learner, gave "
"it the dataset to construct a classifier, and used it to predict the "
"class of the first three data instances. We also use these concepts in "
"the following code that predicts the classes of the selected three "
"instances in the dataset:"
msgstr ""

#: ../../source/tutorial/classification.rst:50
msgid "The script outputs::"
msgstr ""

#: ../../source/tutorial/classification.rst:56
msgid ""
"Logistic regression has made a mistake in the second case, but otherwise "
"predicted correctly. No wonder, since this was also the data it trained "
"from. The following code counts the number of such mistakes in the entire"
" dataset:"
msgstr ""

#: ../../source/tutorial/classification.rst:62
msgid "Probabilistic Classification"
msgstr ""

#: ../../source/tutorial/classification.rst:64
msgid ""
"To find out what is the probability that the classifier assigns to, say, "
"democrat class, we need to call the classifier with an additional "
"parameter that specifies the classification output type."
msgstr ""

#: ../../source/tutorial/classification.rst:69
msgid ""
"The output of the script also shows how badly the logistic regression "
"missed the class in the second case::"
msgstr ""

#: ../../source/tutorial/classification.rst:77
msgid "Cross-Validation"
msgstr ""

#: ../../source/tutorial/classification.rst:81
msgid ""
"Validating the accuracy of classifiers on the training data, as we did "
"above, serves demonstration purposes only. Any performance measure that "
"assesses accuracy should be estimated on the independent test set. Such "
"is also a procedure called `cross-validation "
"<http://en.wikipedia.org/wiki/Cross-validation_(statistics)>`_, which "
"averages the evaluation scores across several runs, each time considering"
" a different training and test subsets as sampled from the original "
"dataset:"
msgstr ""

#: ../../source/tutorial/classification.rst:93
msgid ""
"Cross-validation is expecting a list of learners. The performance "
"estimators also return a list of scores, one for every learner. There was"
" just one learner (`lr`) in the script above, hence an array of length "
"one was returned. The script estimates classification accuracy and area "
"under ROC curve::"
msgstr ""

#: ../../source/tutorial/classification.rst:100
msgid "Handful of Classifiers"
msgstr ""

#: ../../source/tutorial/classification.rst:102
msgid ""
"Orange includes a variety of classification algorithms, most of them "
"wrapped from `scikit-learn <http://scikit-learn.org>`_, including:"
msgstr ""

#: ../../source/tutorial/classification.rst:104
msgid "logistic regression (``Orange.classification.LogisticRegressionLearner``)"
msgstr ""

#: ../../source/tutorial/classification.rst:105
msgid "k-nearest neighbors (``Orange.classification.knn.KNNLearner``)"
msgstr ""

#: ../../source/tutorial/classification.rst:106
msgid ""
"support vector machines (say, "
"``Orange.classification.svm.LinearSVMLearner``)"
msgstr ""

#: ../../source/tutorial/classification.rst:107
msgid "classification trees (``Orange.classification.tree.SklTreeLearner``)"
msgstr ""

#: ../../source/tutorial/classification.rst:108
msgid "random forest (``Orange.classification.RandomForestLearner``)"
msgstr ""

#: ../../source/tutorial/classification.rst:110
msgid ""
"Some of these are included in the code that estimates the probability of "
"a target class on a testing data. This time, training and test datasets "
"are disjoint:"
msgstr ""

#: ../../source/tutorial/classification.rst:121
msgid ""
"For these five data items, there are no major differences between "
"predictions of observed classification algorithms::"
msgstr ""

#: ../../source/tutorial/classification.rst:131
msgid "The following code cross-validates these learners on the titanic dataset."
msgstr ""

#: ../../source/tutorial/classification.rst:135
msgid "Logistic regression wins in area under ROC curve::"
msgstr ""

