# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2015, Orange Data Mining
# This file is distributed under the same license as the Orange Data Mining
# Library package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Orange Data Mining Library 3\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2018-10-29 15:50+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../source/reference/preprocess.rst:5
msgid "Data Preprocessing (``preprocess``)"
msgstr ""

#: ../../source/reference/preprocess.rst:12
msgid ""
"Preprocessing module contains data processing utilities like data "
"discretization, continuization, imputation and transformation."
msgstr ""

#: ../../source/reference/preprocess.rst:16
msgid "Impute"
msgstr ""

#: ../../source/reference/preprocess.rst:18
msgid ""
"Imputation replaces missing values with new values (or omits such "
"features)."
msgstr ""

#: ../../source/reference/preprocess.rst:22
msgid "There are several imputation methods one can use."
msgstr ""

#: ../../source/reference/preprocess.rst:33
msgid "Discretization"
msgstr ""

#: ../../source/reference/preprocess.rst:35
msgid ""
"Discretization replaces continuous features with the corresponding "
"categorical features:"
msgstr ""

#: ../../source/reference/preprocess.rst:40
msgid ""
"The variable in the new data table indicate the bins to which the "
"original values belong. ::"
msgstr ""

#: ../../source/reference/preprocess.rst:53
msgid ""
"Default discretization method (four bins with approximatelly equal number"
" of data instances) can be replaced with other methods."
msgstr ""

#: ../../source/reference/preprocess.rst:101
msgid "_`Discretization Algorithms`"
msgstr ""

#: Orange.preprocess.discretize.EqualWidth:2 of
msgid "Discretization into a fixed number of bins with equal widths."
msgstr ""

#: Orange.preprocess.discretize.EqualWidth:6 of
msgid "Number of bins (default: 4)."
msgstr ""

#: Orange.preprocess.discretize.EqualFreq:2 of
msgid ""
"Discretization into bins with approximately equal number of data "
"instances."
msgstr ""

#: Orange.preprocess.discretize.EqualFreq:7 of
msgid ""
"Number of bins (default: 4). The actual number may be lower if the "
"variable has less than n distinct values."
msgstr ""

#: Orange.preprocess.discretize.EntropyMDL:2 of
msgid ""
"Discretization into bins inferred by recursively splitting the values to "
"minimize the class-entropy. The procedure stops when further splits would"
" decrease the entropy for less than the corresponding increase of minimal"
" description length (MDL). [FayyadIrani93]."
msgstr ""

#: Orange.preprocess.discretize.EntropyMDL:7 of
msgid ""
"If there are no suitable cut-off points, the procedure returns a single "
"bin, which means that the new feature is constant and can be removed."
msgstr ""

#: Orange.preprocess.discretize.EntropyMDL:12 of
msgid ""
"Induce at least one cut-off point, even when its information gain is "
"lower than MDL (default: False)."
msgstr ""

#: ../../source/reference/preprocess.rst:109
msgid "To add a new discretization, derive it from ``Discretization``."
msgstr ""

#: Orange.preprocess.discretize.Discretization:2 of
msgid "Abstract base class for discretization classes."
msgstr ""

#: ../../source/reference/preprocess.rst:114
msgid "Continuization"
msgstr ""

#: ../../source/reference/preprocess.rst:118
msgid ""
"Given a data table, return a new table in which the discretize attributes"
" are replaced with continuous or removed."
msgstr ""

#: ../../source/reference/preprocess.rst:121
msgid ""
"binary variables are transformed into 0.0/1.0 or -1.0/1.0 indicator "
"variables, depending upon the argument ``zero_based``."
msgstr ""

#: ../../source/reference/preprocess.rst:124
msgid ""
"multinomial variables are treated according to the argument "
"``multinomial_treatment``."
msgstr ""

#: ../../source/reference/preprocess.rst:127
msgid "discrete attribute with only one possible value are removed;"
msgstr ""

#: ../../source/reference/preprocess.rst:136
msgid ""
"The class has a number of attributes that can be set either in "
"constructor or, later, as attributes."
msgstr ""

#: ../../source/reference/preprocess.rst:141
msgid ""
"Determines the value used as the \"low\" value of the variable. When "
"binary variables are transformed into continuous or when multivalued "
"variable is transformed into multiple variables, the transformed variable"
" can either have values 0.0 and 1.0 (default, ``zero_based=True``) or "
"-1.0 and 1.0 (``zero_based=False``)."
msgstr ""

#: ../../source/reference/preprocess.rst:149
msgid "Defines the treatment of multinomial variables."
msgstr ""

#: ../../source/reference/preprocess.rst:151
msgid "``Continuize.Indicators``"
msgstr ""

#: ../../source/reference/preprocess.rst:153
msgid ""
"The variable is replaced by indicator variables, each corresponding to "
"one value of the original variable. For each value of the original "
"attribute, only the corresponding new attribute will have a value of one "
"and others will be zero. This is the default behaviour."
msgstr ""

#: ../../source/reference/preprocess.rst:159
msgid ""
"Note that these variables are not independent, so they cannot be used "
"(directly) in, for instance, linear or logistic regression."
msgstr ""

#: ../../source/reference/preprocess.rst:162
msgid ""
"For example, dataset \"titanic\" has feature \"status\" with values "
"\"crew\", \"first\", \"second\" and \"third\", in that order. Its value "
"for the 15th row is \"first\". Continuization replaces the variable with "
"variables \"status=crew\", \"status=first\", \"status=second\" and "
"\"status=third\". After ::"
msgstr ""

#: ../../source/reference/preprocess.rst:171
msgid "we have ::"
msgstr ""

#: ../../source/reference/preprocess.rst:179
msgid ""
"For the 15th row, the variable \"status=first\" has value 1 and the "
"values of the other three variables are 0::"
msgstr ""

#: ../../source/reference/preprocess.rst:205
msgid "``Continuize.FirstAsBase``"
msgstr ""

#: ../../source/reference/preprocess.rst:189
msgid ""
"Similar to the above, except that it creates indicators for all values "
"except the first one, according to the order in the variable's "
":obj:`~Orange.data.DiscreteVariable.values` attribute. If all indicators "
"in the transformed data instance are 0, the original instance had the "
"first value of the corresponding variable."
msgstr ""

#: ../../source/reference/preprocess.rst:195
msgid ""
"If the variable descriptor defines the "
":obj:`~Orange.data.DiscreteVariable.base_value`, the specified value is "
"used as base instead of the first one."
msgstr ""

#: ../../source/reference/preprocess.rst:199
msgid ""
"Continuizing the variable \"status\" with this setting gives variables "
"\"status=first\", \"status=second\" and \"status=third\". If all of them "
"were 0, the status of the original data instance was \"crew\"."
msgstr ""

#: ../../source/reference/preprocess.rst:221
msgid "``Continuize.FrequentAsBase``"
msgstr ""

#: ../../source/reference/preprocess.rst:208
msgid ""
"Like above, except that the most frequent value is used as the base. If "
"there are multiple most frequent values, the one with the lowest index in"
" :obj:`~Orange.data.DiscreteVariable.values` is used. The frequency of "
"values is extracted from data, so this option does not work if only the "
"domain is given."
msgstr ""

#: ../../source/reference/preprocess.rst:215
msgid ""
"Continuizing the Titanic data in this way differs from the above by the "
"attributes sex: instead of \"sex=male\" it constructs \"sex=female\" "
"since there were more females than males on Titanic. ::"
msgstr ""

#: ../../source/reference/preprocess.rst:228
msgid "``Continuize.Remove``"
msgstr ""

#: ../../source/reference/preprocess.rst:224
msgid "Discrete variables are removed. ::"
msgstr ""

#: ../../source/reference/preprocess.rst:236
msgid "``Continuize.RemoveMultinomial``"
msgstr ""

#: ../../source/reference/preprocess.rst:231
msgid ""
"Discrete variables with more than two values are removed. Binary "
"variables are treated the same as in `FirstAsBase`."
msgstr ""

#: ../../source/reference/preprocess.rst:239
msgid "``Continuize.ReportError``"
msgstr ""

#: ../../source/reference/preprocess.rst:239
msgid "Raise an error if there are any multinomial variables in the data."
msgstr ""

#: ../../source/reference/preprocess.rst:251
msgid "``Continuize.AsOrdinal``"
msgstr ""

#: ../../source/reference/preprocess.rst:242
msgid ""
"Multinomial variables are treated as ordinal and replaced by continuous "
"variables with indices within "
":obj:`~Orange.data.DiscreteVariable.values`, e.g. 0, 1, 2, 3..."
msgstr ""

#: ../../source/reference/preprocess.rst:261
msgid "``Continuize.AsNormalizedOrdinal``"
msgstr ""

#: ../../source/reference/preprocess.rst:254
msgid ""
"As above, except that the resulting continuous value will be from range 0"
" to 1, e.g. 0, 0.333, 0.667, 1 for a four-valued variable::"
msgstr ""

#: ../../source/reference/preprocess.rst:266
msgid ""
"If ``True`` the class is replaced by continuous attributes or normalized "
"as well. Multiclass problems are thus transformed to multitarget ones. "
"(Default: ``False``)"
msgstr ""

#: ../../source/reference/preprocess.rst:274
msgid ""
"Construct a domain in which discrete attributes are replaced by "
"continuous. ::"
msgstr ""

#: ../../source/reference/preprocess.rst:280
msgid ""
":obj:`Orange.preprocess.Continuize` calls `DomainContinuizer` to "
"construct the domain."
msgstr ""

#: ../../source/reference/preprocess.rst:283
msgid ""
"Domain continuizers can be given either a dataset or a domain, and return"
" a new domain. When given only the domain, use the most frequent value as"
" the base value."
msgstr ""

#: ../../source/reference/preprocess.rst:287
msgid ""
"By default, the class does not change continuous and class attributes, "
"discrete attributes are replaced with N attributes (``Indicators``) with "
"values 0 and 1."
msgstr ""

#: ../../source/reference/preprocess.rst:292
msgid "Normalization"
msgstr ""

#: Orange.preprocess.Normalize:2 of
msgid ""
"Construct a preprocessor for normalization of features. Given a data "
"table, preprocessor returns a new table in which the continuous "
"attributes are normalized."
msgstr ""

#: Orange.preprocess.Normalize Orange.preprocess.Randomize
#: Orange.preprocess.Remove Orange.preprocess.SelectBestFeatures of
msgid "Parameters"
msgstr ""

#: Orange.preprocess.Normalize:12 of
msgid "**zero_based**"
msgstr ""

#: Orange.preprocess.Normalize:11 of
msgid "bool (default=True)"
msgstr ""

#: Orange.preprocess.Normalize:10 of
msgid ""
"Determines the value used as the “low” value of the variable. It "
"determines the interval for normalized continuous variables (either [-1, "
"1] or [0, 1])."
msgstr ""

#: Orange.preprocess.Normalize:22 of
msgid "**norm_type**"
msgstr ""

#: Orange.preprocess.Normalize:21 of
msgid "NormTypes (default: Normalize.NormalizeBySD)"
msgstr ""

#: Orange.preprocess.Normalize:15 of
msgid ""
"Normalization type. If Normalize.NormalizeBySD, the values are replaced "
"with standardized values by subtracting the average value and dividing by"
" the standard deviation. Attribute zero_based has no effect on this "
"standardization."
msgstr ""

#: Orange.preprocess.Normalize:20 of
msgid ""
"If Normalize.NormalizeBySpan, the values are replaced with normalized "
"values by subtracting min value of the data and dividing by span (max - "
"min)."
msgstr ""

#: Orange.preprocess.Normalize:34 of
msgid "**transform_class**"
msgstr ""

#: Orange.preprocess.Normalize:33 of
msgid "bool (default=False)"
msgstr ""

#: Orange.preprocess.Normalize:25 of
msgid "If True the class is normalized as well."
msgstr ""

#: Orange.preprocess.Normalize:37 Orange.preprocess.Randomize:29
#: Orange.preprocess.Remove:38 of
msgid "Examples"
msgstr ""

#: ../../source/reference/preprocess.rst:298
msgid "Randomization"
msgstr ""

#: Orange.preprocess.Randomize:2 of
msgid ""
"Construct a preprocessor for randomization of classes, attributes and/or "
"metas. Given a data table, preprocessor returns a new table in which the "
"data is shuffled."
msgstr ""

#: Orange.preprocess.Randomize:14 of
msgid "**rand_type**"
msgstr ""

#: Orange.preprocess.Randomize:13 of
msgid "RandTypes (default: Randomize.RandomizeClasses)"
msgstr ""

#: Orange.preprocess.Randomize:11 of
msgid ""
"Randomization type. If Randomize.RandomizeClasses, classes are shuffled. "
"If Randomize.RandomizeAttributes, attributes are shuffled. If "
"Randomize.RandomizeMetas, metas are shuffled."
msgstr ""

#: Orange.preprocess.Randomize:26 of
msgid "**rand_seed**"
msgstr ""

#: Orange.preprocess.Randomize:25 of
msgid "int (optional)"
msgstr ""

#: Orange.preprocess.Randomize:17 of
msgid "Random seed"
msgstr ""

#: ../../source/reference/preprocess.rst:304
msgid "Remove"
msgstr ""

#: Orange.preprocess.Remove:2 of
msgid ""
"Construct a preprocessor for removing constant features/classes and "
"unused values. Given a data table, preprocessor returns a new table and a"
" list of results. In the new table, the constant features/classes and "
"unused values are removed. The list of results consists of two "
"dictionaries. The first one contains numbers of 'removed', 'reduced' and "
"'sorted' features. The second one contains numbers of 'removed', "
"'reduced' and 'sorted' features."
msgstr ""

#: Orange.preprocess.Remove:19 of
msgid "**attr_flags**"
msgstr ""

#: Orange.preprocess.Remove:18 of
msgid "int (default: 0)"
msgstr ""

#: Orange.preprocess.Remove:15 of
msgid ""
"If SortValues, values of discrete attributes are sorted. If "
"RemoveConstant, unused attributes are removed. If RemoveUnusedValues, "
"unused values are removed from discrete attributes. It is possible to "
"merge operations in one by summing several types."
msgstr ""

#: Orange.preprocess.Remove:35 of
msgid "**class_flags: int (default: 0)**"
msgstr ""

#: Orange.preprocess.Remove:22 of
msgid ""
"If SortValues, values of discrete class attributes are sorted. If "
"RemoveConstant, unused class attributes are removed. If "
"RemoveUnusedValues, unused values are removed from discrete class "
"attributes. It is possible to merge operations in one by summing several "
"types."
msgstr ""

#: ../../source/reference/preprocess.rst:309
msgid "Feature selection"
msgstr ""

#: ../../source/reference/preprocess.rst:312
msgid "`Feature scoring`"
msgstr ""

#: ../../source/reference/preprocess.rst:314
msgid ""
"Feature scoring is an assessment of the usefulness of features for "
"prediction of the dependant (class) variable. Orange provides classes "
"that compute the common feature scores for classification and regression."
msgstr ""

#: ../../source/reference/preprocess.rst:318
msgid ""
"The code below computes the information gain of feature \"tear_rate\" in "
"the Lenses dataset:"
msgstr ""

#: ../../source/reference/preprocess.rst:325
msgid ""
"An alternative way of invoking the scorers is to construct the scoring "
"object and calculate the scores for all the features at once, like in the"
" following example:"
msgstr ""

#: ../../source/reference/preprocess.rst:338
msgid ""
"Feature scoring methods work on different feature types (continuous or "
"discrete) and different types of target variables (i.e. in classification"
" or regression problems). Refer to method's `feature_type` and "
"`class_type` attributes for intended type or employ preprocessing methods"
" (e.g. discretization) for conversion between data types."
msgstr ""

#: Orange.preprocess.score.ANOVA:2 of
msgid ""
"A wrapper for `sklearn.feature_selection.univariate_selection.f_classif`."
" The following is the documentation from `scikit-learn <http://scikit-"
"learn.org>`_."
msgstr ""

#: Orange.preprocess.score.ANOVA:5 of
msgid "Compute the ANOVA F-value for the provided sample."
msgstr ""

#: Orange.preprocess.score.ANOVA:7 Orange.preprocess.score.Chi2:17 of
msgid "Read more in the :ref:`User Guide <univariate_feature_selection>`."
msgstr ""

#: Orange.preprocess.score.Chi2:2 of
msgid ""
"A wrapper for `sklearn.feature_selection.univariate_selection.chi2`. The "
"following is the documentation from `scikit-learn <http://scikit-"
"learn.org>`_."
msgstr ""

#: Orange.preprocess.score.Chi2:5 of
msgid "Compute chi-squared stats between each non-negative feature and class."
msgstr ""

#: Orange.preprocess.score.Chi2:7 of
msgid ""
"This score can be used to select the n_features features with the highest"
" values for the test chi-squared statistic from X, which must contain "
"only non-negative features such as booleans or frequencies (e.g., term "
"counts in document classification), relative to the classes."
msgstr ""

#: Orange.preprocess.score.Chi2:12 of
msgid ""
"Recall that the chi-square test measures dependence between stochastic "
"variables, so using this function \"weeds out\" the features that are the"
" most likely to be independent of class and therefore irrelevant for "
"classification."
msgstr ""

#: Orange.preprocess.score.GainRatio:2 of
msgid ""
"Information gain ratio is the ratio between information gain and the "
"entropy of the feature's value distribution. The score was introduced in "
"[Redb558029fc7-Quinlan1986]_ to alleviate overestimation for multi-valued"
" features. See `Wikipedia entry on gain ratio "
"<http://en.wikipedia.org/wiki/Information_gain_ratio>`_."
msgstr ""

#: Orange.preprocess.score.GainRatio:8 of
msgid "J R Quinlan: Induction of Decision Trees, Machine Learning, 1986."
msgstr ""

#: Orange.preprocess.score.Gini:2 of
msgid ""
"Gini impurity is the probability that two randomly chosen instances will "
"have different classes. See `Wikipedia entry on Gini impurity "
"<https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity>`_."
msgstr ""

#: Orange.preprocess.score.InfoGain:2 of
msgid ""
"Information gain is the expected decrease of entropy. See `Wikipedia "
"entry on information gain "
"<http://en.wikipedia.org/wiki/Information_gain_ratio>`_."
msgstr ""

#: Orange.preprocess.score.UnivariateLinearRegression:2 of
msgid ""
"A wrapper for "
"`sklearn.feature_selection.univariate_selection.f_regression`. The "
"following is the documentation from `scikit-learn <http://scikit-"
"learn.org>`_."
msgstr ""

#: Orange.preprocess.score.UnivariateLinearRegression:5 of
msgid "Univariate linear regression tests."
msgstr ""

#: Orange.preprocess.score.UnivariateLinearRegression:7 of
msgid ""
"Linear model for testing the individual effect of each of many "
"regressors. This is a scoring function to be used in a feature selection "
"procedure, not a free standing feature selection procedure."
msgstr ""

#: Orange.preprocess.score.UnivariateLinearRegression:11 of
msgid "This is done in 2 steps:"
msgstr ""

#: Orange.preprocess.score.UnivariateLinearRegression:13 of
msgid ""
"The correlation between each regressor and the target is computed, that "
"is, ((X[:, i] - mean(X[:, i])) * (y - mean_y)) / (std(X[:, i]) * std(y))."
msgstr ""

#: Orange.preprocess.score.UnivariateLinearRegression:16 of
msgid "It is converted to an F score then to a p-value."
msgstr ""

#: Orange.preprocess.score.UnivariateLinearRegression:18 of
msgid ""
"For more on usage see the :ref:`User Guide "
"<univariate_feature_selection>`."
msgstr ""

#: Orange.preprocess.score.FCBF:2 of
msgid "Fast Correlation-Based Filter. Described in:"
msgstr ""

#: Orange.preprocess.score.FCBF:4 of
msgid ""
"Yu, L., Liu, H., Feature selection for high-dimensional data: A fast "
"correlation-based filter solution. 2003. "
"http://www.aaai.org/Papers/ICML/2003/ICML03-111.pdf"
msgstr ""

#: Orange.preprocess.score.ReliefF:2 of
msgid ""
"ReliefF algorithm. Contrary to most other scorers, Relief family of "
"algorithms is not as myoptic but tends to give unreliable results with "
"datasets with lots (hundreds) of features."
msgstr ""

#: Orange.preprocess.score.ReliefF:6 of
msgid ""
"Robnik-Šikonja, M., Kononenko, I. Theoretical and empirical analysis of "
"ReliefF and RReliefF. 2003. http://lkm.fri.uni-"
"lj.si/rmarko/papers/robnik03-mlj.pdf"
msgstr ""

#: ../../source/reference/preprocess.rst:372
msgid ""
"Additionally, you can use the ``score_data()`` method of some learners "
"(\\ :obj:`Orange.classification.LinearRegressionLearner`, "
":obj:`Orange.regression.LogisticRegressionLearner`, "
":obj:`Orange.classification.RandomForestLearner`, and "
":obj:`Orange.regression.RandomForestRegressionLearner`) to obtain the "
"feature scores as calculated by these learners. For example:"
msgstr ""

#: ../../source/reference/preprocess.rst:388
msgid "`Feature selection`"
msgstr ""

#: ../../source/reference/preprocess.rst:390
msgid ""
"We can use feature selection to limit the analysis to only the most "
"relevant or informative features in the dataset."
msgstr ""

#: ../../source/reference/preprocess.rst:393
msgid ""
"Feature selection with a scoring method that works on continuous features"
" will retain all discrete features and vice versa."
msgstr ""

#: ../../source/reference/preprocess.rst:396
msgid ""
"The code below constructs a new dataset consisting of two best features "
"according to the ANOVA method:"
msgstr ""

#: Orange.preprocess.SelectBestFeatures:2 of
msgid ""
"A feature selector that builds a new dataset consisting of either the top"
" `k` features or all those that exceed a given `threshold`. Features are "
"scored using the provided feature scoring `method`. By default it is "
"assumed that feature importance diminishes with decreasing scores."
msgstr ""

#: Orange.preprocess.SelectBestFeatures:7 of
msgid ""
"If both `k` and `threshold` are set, only features satisfying both "
"conditions will be selected."
msgstr ""

#: Orange.preprocess.SelectBestFeatures:10 of
msgid ""
"If `method` is not set, it is automatically selected when presented with "
"the dataset. Datasets with both continuous and discrete features are "
"scored using a method suitable for the majority of features."
msgstr ""

#: Orange.preprocess.SelectBestFeatures:17 of
msgid "**method**"
msgstr ""

#: Orange.preprocess.SelectBestFeatures:16 of
msgid ""
"Orange.preprocess.score.ClassificationScorer, "
"Orange.preprocess.score.SklScorer"
msgstr ""

#: Orange.preprocess.SelectBestFeatures:17 of
msgid "Univariate feature scoring method."
msgstr ""

#: Orange.preprocess.SelectBestFeatures:20 of
msgid "**k**"
msgstr ""

#: Orange.preprocess.SelectBestFeatures:19 of
msgid "int"
msgstr ""

#: Orange.preprocess.SelectBestFeatures:20 of
msgid "The number of top features to select."
msgstr ""

#: Orange.preprocess.SelectBestFeatures:23 of
msgid "**threshold**"
msgstr ""

#: Orange.preprocess.SelectBestFeatures:22 of
msgid "float"
msgstr ""

#: Orange.preprocess.SelectBestFeatures:23 of
msgid "A threshold that a feature should meet according to the provided method."
msgstr ""

#: Orange.preprocess.SelectBestFeatures:39 of
msgid "**decreasing**"
msgstr ""

#: Orange.preprocess.SelectBestFeatures:38 of
msgid "boolean"
msgstr ""

#: Orange.preprocess.SelectBestFeatures:26 of
msgid ""
"The order of feature importance when sorted from the most to the least "
"important feature."
msgstr ""

#: ../../source/reference/preprocess.rst:409
msgid "Preprocessors"
msgstr ""

