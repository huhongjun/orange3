# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2015, Orange Data Mining
# This file is distributed under the same license as the Orange Data Mining
# Library package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Orange Data Mining Library 3\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2018-10-29 15:50+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../source/reference/distance.rst:3
msgid "Distance (``distance``)"
msgstr ""

#: ../../source/reference/distance.rst:5
msgid ""
"The following example demonstrates how to compute distances between all "
"data instances from Iris:"
msgstr ""

#: ../../source/reference/distance.rst:16
msgid "To compute distances between all columns, we set `axis` to 0."
msgstr ""

#: ../../source/reference/distance.rst:24
msgid ""
"Finally, we can compute distances between all pairs of rows from two "
"tables."
msgstr ""

#: ../../source/reference/distance.rst:32
msgid ""
"Most metrics can be fit on training data to normalize values and handle "
"missing data. We do so by calling the constructor without arguments or "
"with parameters, such as `normalize`, and then pass the data to method "
"`fit`."
msgstr ""

#: ../../source/reference/distance.rst:43
msgid ""
"The above distances are computed on the first three rows of `iris2`, "
"normalized by means and variances computed from `iris1`."
msgstr ""

#: ../../source/reference/distance.rst:46
msgid "Here are five closest neighbors of `iris2[0]` from `iris1`::"
msgstr ""

#: ../../source/reference/distance.rst:58
msgid "All distances share a common interface."
msgstr ""

#: Orange.distance.Distance:2 of
msgid "Base class for construction of distances models (:obj:`DistanceModel`)."
msgstr ""

#: Orange.distance.Distance:4 of
msgid ""
"Distances can be computed between all pairs of rows in one table, or "
"between pairs where one row is from one table and one from another."
msgstr ""

#: Orange.distance.Distance:7 of
msgid ""
"If `axis` is set to `0`, the class computes distances between all pairs "
"of columns in a table. Distances between columns from separate tables are"
" probably meaningless, thus unsupported."
msgstr ""

#: Orange.distance.Distance:11 of
msgid "The class can be used as follows:"
msgstr ""

#: Orange.distance.Distance:13 of
msgid ""
"Constructor is called only with keyword argument `axis` that specifies "
"the axis over which the distances are computed, and with other subclass-"
"specific keyword arguments."
msgstr ""

#: Orange.distance.Distance:16 of
msgid ""
"Next, we call the method `fit(data)` to produce an instance of "
":obj:`DistanceModel`; the instance stores any parameters needed for "
"computation of distances, such as statistics for normalization and "
"handling of missing data."
msgstr ""

#: Orange.distance.Distance:20 of
msgid ""
"We can then call the :obj:`DistanceModel` with data to compute the "
"distance between its rows or columns, or with two data tables to compute "
"distances between all pairs of rows."
msgstr ""

#: Orange.distance.Distance:24 of
msgid ""
"The second, shorter way to use this class is to call the constructor with"
" one or two data tables and any additional keyword arguments. Constructor"
" will execute the above steps and return :obj:`~Orange.misc.DistMatrix`. "
"Such usage is here for backward compatibility, practicality and "
"efficiency."
msgstr ""

#: Orange.distance.Distance:40 of
msgid "Args:"
msgstr ""

#: Orange.distance.Distance:30 of
msgid ""
"e1 (:obj:`~Orange.data.Table` or :obj:`~Orange.data.Instance` or"
"                 :obj:`np.ndarray` or `None`):"
msgstr ""

#: Orange.distance.Distance:31 of
msgid "data on which to train the model and compute the distances"
msgstr ""

#: Orange.distance.Distance:33 of
msgid ""
"e2 (:obj:`~Orange.data.Table` or :obj:`~Orange.data.Instance` or"
"                 :obj:`np.ndarray` or `None`):"
msgstr ""

#: Orange.distance.Distance:33 of
msgid ""
"if present, the class computes distances with pairs coming from the two "
"tables"
msgstr ""

#: Orange.distance.Distance:36 Orange.distance.Distance:44 of
msgid "axis (int):"
msgstr ""

#: Orange.distance.Distance:36 Orange.distance.Distance:44 of
msgid ""
"axis over which the distances are computed, 1 (default) for rows, 0 for "
"columns"
msgstr ""

#: Orange.distance.Distance:40 Orange.distance.Distance:48 of
msgid "impute (bool):"
msgstr ""

#: Orange.distance.Distance:39 Orange.distance.Distance:47 of
msgid ""
"if `True` (default is `False`), nans in the computed distances are "
"replaced with zeros, and infs with very large numbers."
msgstr ""

#: Orange.distance.Distance:48 of
msgid "Attributes:"
msgstr ""

#: Orange.distance.Distance:50 of
msgid "The capabilities of the metrics are described with class attributes."
msgstr ""

#: Orange.distance.Distance:52 of
msgid ""
"If class attribute `supports_discrete` is `True`, the distance also uses "
"discrete attributes to compute row distances. The use of discrete "
"attributes depends upon the type of distance; e.g. Jaccard distance "
"observes whether the value is zero or non-zero, while Euclidean and "
"Manhattan distance observes whether a pair of values is same or "
"different."
msgstr ""

#: Orange.distance.Distance:58 of
msgid ""
"Class attribute `supports_missing` indicates that the distance can cope "
"with missing data. In such cases, letting the distance handle it should "
"be preferred over pre-imputation of missing values."
msgstr ""

#: Orange.distance.Distance:62 of
msgid ""
"Class attribute `supports_normalization` indicates that the constructor "
"accepts an argument `normalize`. If set to `True`, the metric will "
"attempt to normalize the values in a sense that each attribute will have "
"equal influence. For instance, the Euclidean distance subtract the mean "
"and divides the result by the deviation, while Manhattan distance uses "
"the median and MAD."
msgstr ""

#: Orange.distance.Distance:69 of
msgid ""
"If class attribute `supports_sparse` is `True`, the class will handle "
"sparse data. Currently, all classes that do handle it rely on fallbacks "
"to SKL metrics. These, however, do not support discrete data and missing "
"values, and will fail silently."
msgstr ""

#: ../../source/reference/distance.rst:63
msgid "Handling discrete and missing data"
msgstr ""

#: ../../source/reference/distance.rst:65
msgid ""
"Discrete data is handled as appropriate for the particular distance. For "
"instance, the Euclidean distance treats a pair of values as either the "
"same or different, contributing either 0 or 1 to the squared sum of "
"differences. In other cases -- particularly in Jaccard and cosine "
"distance, discrete values are treated as zero or non-zero."
msgstr ""

#: ../../source/reference/distance.rst:71
msgid ""
"Missing data is not simply imputed. We assume that values of each "
"variable are distributed by some unknown distribution and compute - "
"without assuming a particular distribution shape - the expected distance."
" For instance, for the Euclidean distance it turns out that the expected "
"squared distance between a known and a missing value equals the square of"
" the known value's distance from the mean of the missing variable, plus "
"its variance."
msgstr ""

#: ../../source/reference/distance.rst:81
msgid "Supported distances"
msgstr ""

#: ../../source/reference/distance.rst:84
msgid "Euclidean distance"
msgstr ""

#: ../../source/reference/distance.rst:86
msgid ""
"For numeric values, the Euclidean distance is the square root of sums of "
"squares of pairs of values from rows or columns. For discrete values, 1 "
"is added if the two values are different."
msgstr ""

#: ../../source/reference/distance.rst:90
msgid ""
"To put all numeric data on the same scale, and in particular when working"
" with a mixture of numeric and discrete data, it is recommended to enable"
" normalization by adding `normalize=True` to the constructor. With this, "
"numeric values are normalized by subtracting their mean and divided by "
"deviation multiplied by the square root of two. The mean and deviation "
"are computed on the training data, if the `fit` method is used. When "
"computing distances between two tables and without explicitly calling "
"`fit`, means and variances are computed from the first table only. Means "
"and variances are always computed from columns, disregarding the axis "
"over which we compute the distances, since columns represent variables "
"and hence come from a certain distribution."
msgstr ""

#: ../../source/reference/distance.rst:102
msgid ""
"As described above, the expected squared difference between a known and a"
" missing value equals the squared difference between the known value and "
"the mean, plus the variance. The squared difference between two unknown "
"values equals twice the variance."
msgstr ""

#: ../../source/reference/distance.rst:107
msgid ""
"For normalized data, the difference between a known and missing numeric "
"value equals the square of the known value + 0.5. The difference between "
"two missing values is 1."
msgstr ""

#: ../../source/reference/distance.rst:111
msgid ""
"For discrete data, the expected difference between a known and a missing "
"value equals the probablity that the two values are different, which is 1"
" minus the probability of the known value. If both values are missing, "
"the probability of them being different equals 1 minus the sum of squares"
" of all probabilities (also known as the Gini index)."
msgstr ""

#: ../../source/reference/distance.rst:119
msgid "Manhattan distance"
msgstr ""

#: ../../source/reference/distance.rst:121
msgid "Manhattan distance is the sum of absolute pairwise distances."
msgstr ""

#: ../../source/reference/distance.rst:123
msgid ""
"Normalization and treatment of missing values is similar as in the "
"Euclidean distance, except that medians and median absolute distance from"
" the median (MAD) are used instead of means and deviations."
msgstr ""

#: ../../source/reference/distance.rst:127
msgid ""
"For discrete values, distances are again 0 or 1, hence the Manhattan "
"distance for discrete columns is the same as the Euclidean."
msgstr ""

#: ../../source/reference/distance.rst:131
msgid "Cosine distance"
msgstr ""

#: ../../source/reference/distance.rst:133
msgid ""
"Cosine similarity is the dot product divided by the product of lengths "
"(where the length is the square of dot product of a row/column with "
"itself). Cosine distance is computed by subtracting the similarity from "
"one."
msgstr ""

#: ../../source/reference/distance.rst:137
msgid ""
"In calculation of dot products, missing values are replaced by means. In "
"calculation of lengths, the contribution of a missing value equals the "
"square of the mean plus the variance. (The difference comes from the fact"
" that in the former case the missing values are independent.)"
msgstr ""

#: ../../source/reference/distance.rst:142
msgid ""
"Non-zero discrete values are replaced by 1. This introduces the notion of"
" a \"base value\", which is the first in the list of possible values. In "
"most cases, this will only make sense for indicator (i.e. two-valued, "
"boolean attributes)."
msgstr ""

#: ../../source/reference/distance.rst:146
msgid "Cosine distance does not support any column-wise normalization."
msgstr ""

#: ../../source/reference/distance.rst:149
msgid "Jaccard distance"
msgstr ""

#: ../../source/reference/distance.rst:151
msgid ""
"Jaccard similarity between two sets is defined as the size of their "
"intersection divided by the size of the union. Jaccard distance is "
"computed by subtracting the similarity from one."
msgstr ""

#: ../../source/reference/distance.rst:155
msgid ""
"In Orange, attribute values are interpreted as membership indicator. In "
"row-wise distances, columns are interpreted as sets, and non-zero values "
"in a row (including negative values of numeric features) indicate that "
"the row belongs to the particular sets. In column-wise distances, rows "
"are sets and values indicate the sets to which the column belongs."
msgstr ""

#: ../../source/reference/distance.rst:161
msgid ""
"For missing values, relative frequencies from the training data are used "
"as probabilities for belonging to a set. That is, for row-wise distances,"
" we compute the relative frequency of non-zero values in each column, and"
" vice-versa for column-wise distances. For intersection (union) of sets, "
"we then add the probability of belonging to both (any of) the two sets "
"instead of adding a 0 or 1."
msgstr ""

#: ../../source/reference/distance.rst:169
msgid "SpearmanR, AbsoluteSpearmanR, PearsonR, AbsolutePearsonR"
msgstr ""

#: ../../source/reference/distance.rst:171
msgid ""
"The four correlation-based distance measure equal (1 - the correlation "
"coefficient) / 2. For `AbsoluteSpearmanR` and `AbsolutePearsonR`, the "
"absolute value of the coefficient is used."
msgstr ""

#: ../../source/reference/distance.rst:175
msgid "These distances do not handle missing or discrete values."
msgstr ""

#: ../../source/reference/distance.rst:178
msgid "Mahalanobis distance"
msgstr ""

#: ../../source/reference/distance.rst:180
msgid ""
"Mahalanobis distance is similar to cosine distance, except that the data "
"is projected into the PCA space."
msgstr ""

#: ../../source/reference/distance.rst:183
msgid "Mahalanobis distance does not handle missing or discrete values."
msgstr ""

